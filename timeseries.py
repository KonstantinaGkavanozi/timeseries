# -*- coding: utf-8 -*-
"""timeseries.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1adoK4vdUp3wRF53qcR4K47YHa6epuuMM
"""
import mpld3
import matplotlib.pyplot as plt
import pandas as pd
import os
import numpy as np
from mpl_toolkits.mplot3d import Axes3D
from statsmodels.tsa.stattools import acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.stats.diagnostic import acorr_ljungbox
from statsmodels.tsa.arima_process import arma_generate_sample, arma_acf
from scipy.stats import norm
from statsmodels.tsa.arima.model import ARIMA
import statsmodels.api as sm
import pmdarima as pmd
#from nolitsa import data, delay, dimension, d2, utils
import nolds
from sklearn.neighbors import KDTree


"""Read the file contents"""

# read a file named ContestData.dat. It is a 600 x 50 array of floats, separated by spaces and newlines.
file = 'ContestData.dat.txt'
arr = np.loadtxt(file)

team_id = 9
# keep the team_id column
arr = arr[:, team_id].reshape(1, 600)[0]
# plot the data
plt.plot(arr)
plt.title("Team 9 Time Series")
plt.savefig("team9.png")

"""##First try Moving average smoothing"""

def rolling_window(xV, window):
    '''
    returns moving average of a time series xV
    with length of window
    '''
    xV = xV.flatten()
    return np.convolve(xV, np.ones(window) / window, mode='same')

def moving_average(arr, window):
    arr = np.array(arr)
    n = arr.shape[0]
    print(n)
    smoothed = np.zeros(n)
    for i in range(n):
        smoothed[i] = np.mean(arr[max(0,i-window):min(n,i+window)])
    difference = arr[:len(smoothed)] - smoothed
    return difference

def plot_moving_average_difference(arr, window):
    difference = rolling_window(arr, window)
    plt.figure(figsize=(20, 5))
    plt.plot(difference, label='Difference')
    plt.legend()
    plt.title("Moving Average")
    plt.show()

moving_avg_arr = rolling_window(arr, 5)
plot_moving_average_difference(arr, 5)

"""###Try the Polynomial Function

"""

def polynomial_fit(xV, p):
    '''
    fit to a given time series with a polynomial of a given order.
    :param xV: vector of length 'n' of the time series
    :param p: the order of the polynomial to be fitted
    :return: vector of length 'n' of the fitted time series
    '''
    n = xV.shape[0]
    xV = xV[:]
    if p > 1:
        tV = np.arange(n)
        bV = np.polyfit(x=tV, y=xV, deg=p)
        muV = np.polyval(p=bV, x=tV)
    else:
        muV = np.full(shape=n, fill_value=np.nan)
    return muV

# keep the data - fit of degree 2
arr_2_fit = arr - polynomial_fit(arr, 2)

# plot arr_2_fit in a beautiful way
fig, ax = plt.subplots()
# make it wide
fig.set_figwidth(15)
ax.plot(arr_2_fit)
ax.title.set_text('Data minus fit of degree 2')

plt.savefig("fit_polynomial.png")

def fit_n_degree(n, row):
    # fit a polynomial of degree n
    pol = np.polyfit(np.arange(len(row)), row, n)
    return np.polyval(pol, np.arange(len(row)))

# keep the data - fit of degree 2
arr_2_fit = arr - fit_n_degree(2, arr)

# plot arr_2_fit in a beautiful way
fig, ax = plt.subplots()
# make it wide
fig.set_figwidth(15)
ax.plot(arr_2_fit)
ax.title.set_text('Data minus fit of degree 2')

plt.savefig("fit_polynomial.png")

"""###Use the first Differences Method

"""

def n_diffed(n, row):
    # difference of n elements
    return np.diff(row, n)

arr_1_diff = n_diffed(1, arr)

# plot arr_1_diff in a beautiful way
fig, ax = plt.subplots()
# make it wide
fig.set_figwidth(15)
ax.plot(arr_1_diff)
ax.title.set_text('Difference of the data with n = 1')

plt.savefig("diffed.png")

"""###Calculating Autocorrelation and Partial Autocorrelation for White Noise Check"""

def get_acf(xV, lags=200, alpha=0.05, show=True):
    '''
    calculate acf of timeseries xV to lag (lags) and show
    figure with confidence interval with (alpha)
    '''
    acfV = acf(xV, nlags=lags)[1:]
    z_inv = norm.ppf(1 - alpha / 2)
    upperbound95 = z_inv / np.sqrt(xV.shape[0])
    lowerbound95 = -upperbound95
    if show:
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(np.arange(1, lags + 1), acfV, marker='o')
        ax.axhline(upperbound95, linestyle='--', color='red', label=f'Conf. Int {(1 - alpha) * 100}%')
        ax.axhline(lowerbound95, linestyle='--', color='red')
        ax.set_title('Autocorrelation')
        ax.set_xlabel('Lag')
        ax.set_xticks(np.arange(1, lags + 1))
        ax.grid(linestyle='--', linewidth=0.5, alpha=0.15)
        ax.legend()
    return acfV

def get_pacf(xV, lags=200, alpha=0.05, show=True):
    '''
    calculate pacf of timeseries xV to lag (lags) and show
    figure with confidence interval with (alpha)
    '''
    pacfV = pacf(xV, nlags=lags, method='ols-adjusted')[1:]
    z_inv = norm.ppf(1 - alpha / 2)
    upperbound95 = z_inv / np.sqrt(xV.shape[0])
    lowerbound95 = -upperbound95
    if show:
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(np.arange(1, lags + 1), pacfV, marker='o')
        ax.axhline(upperbound95, linestyle='--', color='red', label=f'Conf. Int {(1 - alpha) * 100}%')
        ax.axhline(lowerbound95, linestyle='--', color='red')
        ax.set_title('Partial Autocorrelation')
        ax.set_xlabel('Lag')
        ax.set_xticks(np.arange(1, lags + 1))
        ax.grid(linestyle='--', linewidth=0.5, alpha=0.15)
        ax.legend()
    return pacfV

get_acf(arr_1_diff)

get_pacf(arr_1_diff)

"""###Finding the Best Linear Model

"""

#Finding the best model for the given timeseries
def arimamodel(xV):
    '''
    BUILT-IN SOLUTION FOR DETECTING BEST ARIMA MODEL MINIMIZING AIC
    https://alkaline-ml.com/pmdarima/index.html
    '''
    autoarim = pmd.auto_arima(xV,start_p=1, start_q=1,
                                     max_p=10, max_q=10,
                                     test="adf", stepwise=False,
                                     trace=True, information_criterion='aic')
    return autoarim

model = arimamodel(arr)
print(model)

def fit_arima_model(xV, p, q, d=0, show=False):
    '''
    fit ARIMA(p, d, q) in xV
    returns: summary (table), fittedvalues, residuals, model, AIC
    '''
    try:
        model = ARIMA(xV, order=(p, d, q)).fit()
    except:
        return np.nan
    summary = model.summary()
    fittedvalues = model.fittedvalues
    fittedvalues = np.array(fittedvalues).reshape(-1, 1)
    resid = model.resid
    if show:
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(xV, label='Original', color='blue')
        ax.plot(fittedvalues, label='FittedValues', color='red', linestyle='--', alpha=0.9)
        ax.legend()
        ax.set_title(f'ARIMA({p}, {d}, {q})')
        fig, ax = plt.subplots(2, 1, figsize=(14, 8))
        ax[0].hist(resid, label='Residual')
        ax[1].scatter(np.arange(len(resid)), resid)
        plt.title('Residuals')
        plt.legend()
    return summary, fittedvalues, resid, model, model.aic

#####Fit of an ARMA model
summary, fittedvalues, resid, model, aic = fit_arima_model(xV=arr, p=3, q=2, d=0, show=True)
print(summary)

"""###Forecasting for ARIMA when timeseries is 1a

"""

def nrmse(y_true, y_pred):
    """
    Calculate the Normalized Root Mean Squared Error (NRMSE) between two arrays.

    Parameters:
    y_true : array-like
        The true values.
    y_pred : array-like
        The predicted values.

    Returns:
    float
        The NRMSE value.
    """
    mse = np.mean((y_true - y_pred) ** 2)
    rmse = np.sqrt(mse)
    range_values = np.max(y_true) - np.min(y_true)
    nrmse_value = rmse / range_values
    return nrmse_value

split_point = 450
train_set = moving_avg_arr[:split_point]
evalution_set = moving_avg_arr[split_point:]
y_true = arr[450:]

def calculate_fitting_error(xV, model, Tmax=20, show=False):
    '''
    calculate fitting error with NRMSE for given model in timeseries xV
    till prediction horizon Tmax
    returns:
    nrmseV
    preds: for timesteps T=1, 2, 3
    '''
    nrmseV = np.full(shape=Tmax, fill_value=np.nan)
    nobs = len(xV)
    xV_std = np.std(xV)
    vartar = np.sum((xV - np.mean(xV)) ** 2)
    predM = []
    tmin = np.max(
        [len(model.arparams), len(model.maparams), 1])  # start prediction after getting all lags needed from model
    for T in np.arange(1, Tmax):
        errors = []
        predV = np.full(shape=nobs, fill_value=np.nan)
        for t in np.arange(tmin, nobs - T):
            pred_ = model.predict(start=t, end=t + T - 1, dynamic=True)
            # predV.append(pred_[-1])
            ytrue = xV[t + T - 1]
            predV[t + T - 1] = pred_[-1]
            error = pred_[-1] - ytrue
            errors.append(error)
        predM.append(predV)
        errors = np.array(errors)
        mse = np.mean(np.power(errors, 2))
        rmse = np.sqrt(mse)
        nrmseV[T] = (rmse / xV_std)
        # nrmseV[T] = (np.sum(errors**2) / vartar)
    if show:
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(np.arange(1, Tmax), nrmseV[1:], marker='x', label='NRMSE');
        ax.axhline(1, color='red', linestyle='--');
        ax.set_title('Fitting Error')
        ax.legend()
        ax.set_xlabel('T')
        ax.set_xticks(np.arange(1, Tmax))
        plt.show()
        # #plot multistep prediction for T=1, 2, 3
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(xV, label='original')
        colors = ['red', 'green', 'black']
        for i, preds in enumerate(predM[:3]):
            ax.plot(preds, color=colors[i], linestyle='--', label=f'T={i + 1}', alpha=0.7)
        ax.legend(loc='best')
        plt.show()
    return nrmseV, predM


def predict_multistep(model, Tmax=10, show=False):
    tmin = np.max(
        [len(model.arparams), len(model.maparams), 1])  # start prediction after getting all lags needed from model
    preds = model.predict(start=tmin, end=Tmax, dynamic=True)
    if show:
        fig, ax = plt.subplots(1, 1, figsize=(14, 8))
        ax.plot(preds)
        ax.set_title('Multistep prediction')
        ax.set_xlabel('T')
        plt.show
    return preds

###FIT MODEL
best_p = 3
best_q = 2
summary, fittedvalues, resid, model, aic = fit_arima_model(xV=train_set, p=best_p, q=best_q, d=0, show=True)

# ###CHECK GOODNESS OF FITTED MODEL
plt.figure()
plt.hist(resid)
acfV = get_acf(xV=resid, lags=10, alpha=0.05, show=True)
# # ####GET FIT ERROR
nrmseV, predM = calculate_fitting_error(train_set, model, Tmax=10, show=True)

model_1a = sm.tsa.ARIMA(train_set, order=(3,0,2))
model_1a_fit = model_1a.fit()

forecast_1a_values = []
nmrse_1a_scores = []

for i in range(450, len(arr) - 4):
  forecast_1a = model_1a_fit.predict(start=i, end=i+4)
  forecast_1a_values.append(forecast_1a)
  true_values = arr[i+1 : i+5]

for j in range(450, len(arr)-5):
  true_values = arr[j+1: j+6]
  forecast_1a = model_1a_fit.predict(start=j, end=j+4)
  nrmse_score = nrmse(true_values, forecast_1a)

  nmrse_1a_scores.append(nrmse_score)

print(nmrse_1a_scores)

train_set = arr_1_diff[:450]
evaluation_set = arr_1_diff[450:600]

model_1b = sm.tsa.ARIMA(train_set, order=(3,0,2))
model_1b_fit = model_1b.fit()

forecast_1b_values = []
nmrse_1b_scores = []

for i in range(450, len(arr) - 4):
  forecast_1b = model_1b_fit.predict(start=i, end=i+4)
  forecast_1b_values.append(forecast_1b)
  true_values = arr[i+1 : i+5]

for j in range(450, len(arr)-5):
  true_values = arr[j+1: j+6]
  forecast_1b = model_1b_fit.predict(start=j, end=j+4)
  nrmse_score = nrmse(true_values, forecast_1a)

  nmrse_1b_scores.append(nrmse_score)

print(nmrse_1b_scores)

diff = [x - y for x, y in zip(nmrse_1a_scores, nmrse_1b_scores)]

positive = 0
negative = 0

for i in range(len(diff)):
  if diff[i] > 0:
    positive = positive + 1

  else:
    negative = negative + 1

print(f"positives: {positive}")

print(f"negatives: {negative}")